{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYFToerwfrYl1d7DXnMrZf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdelhibabu/SubDataBase-0.91s-Reproducibility/blob/main/cibo_vfl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQxTWYbEb-BP",
        "outputId": "6fcff986-7ad5-4d16-faab-009e2afa7eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Collecting botorch\n",
            "  Downloading botorch-0.16.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting gpytorch\n",
            "  Downloading gpytorch-1.15.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Collecting pyre_extensions (from botorch)\n",
            "  Downloading pyre_extensions-0.0.32-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting linear_operator>=0.6 (from botorch)\n",
            "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pyro-ppl>=1.8.4 (from botorch)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from botorch) (1.16.3)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.12/dist-packages (from botorch) (1.0.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.12/dist-packages (from botorch) (3.6.0)\n",
            "Collecting jaxtyping (from gpytorch)\n",
            "  Downloading jaxtyping-0.3.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.12/dist-packages (from gpytorch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8.4->botorch)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.3)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch)\n",
            "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting typing-inspect (from pyre_extensions->botorch)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre_extensions->botorch)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading botorch-0.16.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gpytorch-1.15.1-py3-none-any.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.8/287.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxtyping-0.3.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyre_extensions-0.0.32-py3-none-any.whl (12 kB)\n",
            "Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: pyro-api, wadler-lindig, mypy-extensions, typing-inspect, jaxtyping, pyro-ppl, pyre_extensions, linear_operator, gpytorch, botorch\n",
            "Successfully installed botorch-0.16.1 gpytorch-1.15.1 jaxtyping-0.3.7 linear_operator-0.6 mypy-extensions-1.1.0 pyre_extensions-0.0.32 pyro-api-0.1.2 pyro-ppl-1.9.1 typing-inspect-0.9.0 wadler-lindig-0.1.7\n"
          ]
        }
      ],
      "source": [
        "pip install torch botorch gpytorch scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# BoTorch & GPyTorch imports\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.fit import fit_gpytorch_mll\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "from botorch.acquisition import UpperConfidenceBound\n",
        "from botorch.optim import optimize_acqf\n",
        "from gpytorch.kernels import ScaleKernel, MaternKernel\n",
        "\n",
        "# ==========================================\n",
        "# 1. VFL Simulation Environment (MAB-VFL Baseline Style)\n",
        "# ==========================================\n",
        "\n",
        "class BottomModel(nn.Module):\n",
        "    \"\"\"Client model: Projects raw features to an embedding.\"\"\"\n",
        "    def __init__(self, input_dim, embed_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, embed_dim),\n",
        "            nn.ReLU() # Embeddings are typically activated\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class TopModel(nn.Module):\n",
        "    \"\"\"Server model: Aggregates embeddings and predicts class.\"\"\"\n",
        "    def __init__(self, total_embed_dim, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(total_embed_dim, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, fused_embedding):\n",
        "        return self.net(fused_embedding)\n",
        "\n",
        "class VFLSystem:\n",
        "    def __init__(self, n_clients, feature_dim, num_classes=10):\n",
        "        self.n_clients = n_clients\n",
        "        self.feature_dim = feature_dim\n",
        "        # Distribute features evenly\n",
        "        self.client_feat_dim = feature_dim // n_clients\n",
        "        self.embed_dim = 8\n",
        "\n",
        "        self.clients = nn.ModuleList([\n",
        "            BottomModel(self.client_feat_dim, self.embed_dim)\n",
        "            for _ in range(n_clients)\n",
        "        ])\n",
        "        self.server = TopModel(self.embed_dim * n_clients, num_classes)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward_pass(self, x_parts):\n",
        "        # Unsqueeze each embedding to add a batch dimension (1, embed_dim)\n",
        "        # before concatenating along dim=1.\n",
        "        embeddings = [client(x).unsqueeze(0) for client, x in zip(self.clients, x_parts)]\n",
        "        fused = torch.cat(embeddings, dim=1)\n",
        "        logits = self.server(fused)\n",
        "        return logits\n",
        "\n",
        "    def get_loss(self, x_parts, target_label):\n",
        "        \"\"\"Returns loss. (Higher loss = Successful Attack)\"\"\"\n",
        "        logits = self.forward_pass(x_parts)\n",
        "        # We target Untargeted Attack: Maximize CrossEntropy with True Label\n",
        "        loss = self.criterion(logits, target_label.unsqueeze(0))\n",
        "        return loss\n",
        "\n",
        "# ==========================================\n",
        "# 2. CIBO-VFL Attack Engine\n",
        "# ==========================================\n",
        "\n",
        "class CIBOAttacker:\n",
        "    def __init__(self, vfl_system, budget_T, latent_dim_per_client=2):\n",
        "        self.vfl = vfl_system\n",
        "        self.T = budget_T\n",
        "        self.d_sub = latent_dim_per_client\n",
        "\n",
        "        # Total latent dimension = (M clients * d_sub)\n",
        "        # We structure latent space so Z = [z_client_1, z_client_2, ...]\n",
        "        self.total_latent_dim = self.vfl.n_clients * self.d_sub\n",
        "\n",
        "        # History\n",
        "        self.train_x = [] # Latent vectors Z\n",
        "        self.train_y = [] # Losses\n",
        "\n",
        "        # GP Model\n",
        "        self.gp = None\n",
        "\n",
        "        # Client Importance Scores (Initialized Uniformly)\n",
        "        self.beta = torch.ones(self.vfl.n_clients) / self.vfl.n_clients\n",
        "\n",
        "    def upsample_projection(self, z_flat):\n",
        "        \"\"\"\n",
        "        Maps latent vector Z (d) -> Perturbation Delta (D).\n",
        "        We upsample each client's segment of Z separately.\n",
        "        \"\"\"\n",
        "        z_reshaped = z_flat.view(self.vfl.n_clients, self.d_sub)\n",
        "        deltas = []\n",
        "\n",
        "        for i in range(self.vfl.n_clients):\n",
        "            # Bilinear upsampling 1D (using interpolate)\n",
        "            # z_c: [d_sub] -> [1, 1, d_sub] -> [1, 1, feat_dim]\n",
        "            z_c = z_reshaped[i].view(1, 1, -1)\n",
        "            delta_c = torch.nn.functional.interpolate(\n",
        "                z_c,\n",
        "                size=self.vfl.client_feat_dim,\n",
        "                mode='linear',\n",
        "                align_corners=False\n",
        "            )\n",
        "            deltas.append(delta_c.view(-1))\n",
        "\n",
        "        return deltas # List of perturbations per client\n",
        "\n",
        "    def update_surrogate_model(self):\n",
        "        \"\"\"Fits GP with ARD kernel to observation history.\"\"\"\n",
        "        if len(self.train_x) < 5: return # Not enough data yet\n",
        "\n",
        "        X = torch.stack(self.train_x).double()\n",
        "        Y = torch.stack(self.train_y).unsqueeze(-1).double()\n",
        "\n",
        "        # Define GP with ARD (one lengthscale per latent dim)\n",
        "        self.gp = SingleTaskGP(X, Y)\n",
        "        self.gp.covar_module = ScaleKernel(\n",
        "            MaternKernel(ard_num_dims=self.total_latent_dim)\n",
        "        )\n",
        "\n",
        "        mll = ExactMarginalLogLikelihood(self.gp.likelihood, self.gp)\n",
        "        fit_gpytorch_mll(mll)\n",
        "\n",
        "        # --- CIBO CORE: EXTRACT IMPORTANCE ---\n",
        "        # Get lengthscales: shape (1, total_latent_dim)\n",
        "        ls = self.gp.covar_module.base_kernel.lengthscale.detach().view(-1)\n",
        "\n",
        "        # Aggregation: beta_client = sum(1/lengthscale) for that client's latent dims\n",
        "        ls_reshaped = ls.view(self.vfl.n_clients, self.d_sub)\n",
        "        inv_ls = 1.0 / (ls_reshaped + 1e-6) # Avoid div by zero\n",
        "        self.beta = inv_ls.sum(dim=1)\n",
        "\n",
        "        print(f\"  [Info] Updated Client Importance: {self.beta.numpy().round(3)}\")\n",
        "\n",
        "    def select_clients(self):\n",
        "        \"\"\"Select Top-T clients based on beta scores.\"\"\"\n",
        "        # Add small noise to break ties/encourage exploration initially\n",
        "        noisy_beta = self.beta + torch.randn_like(self.beta) * 0.01\n",
        "        _, indices = torch.topk(noisy_beta, self.T)\n",
        "        return indices.tolist()\n",
        "\n",
        "    def run_attack(self, x_target, y_target, n_iters=30, update_freq=5):\n",
        "        print(f\"\\n--- Starting CIBO-VFL Attack (T={self.T}) ---\")\n",
        "        x_parts_orig = torch.split(x_target, self.vfl.client_feat_dim)\n",
        "\n",
        "        best_loss = -float('inf')\n",
        "\n",
        "        # Initial Random Sampling (Warmup)\n",
        "        # We perturb ALL clients randomly initially to gather sensitivity data\n",
        "        z = torch.randn(self.total_latent_dim)\n",
        "\n",
        "        for i in range(n_iters):\n",
        "            # 1. Select Clients\n",
        "            if i < 5:\n",
        "                # Warmup: random selection or all\n",
        "                active_clients = list(range(self.vfl.n_clients))\n",
        "            else:\n",
        "                active_clients = self.select_clients()\n",
        "\n",
        "                # 2. Bayesian Optimization Step\n",
        "                # Find z that maximizes acquisition function (UCB)\n",
        "                if self.gp is not None:\n",
        "                    UCB = UpperConfidenceBound(self.gp, beta=0.1)\n",
        "                    # Optimize z in [-2, 2] bound\n",
        "                    bounds = torch.stack([-2.0 * torch.ones(self.total_latent_dim),\n",
        "                                           2.0 * torch.ones(self.total_latent_dim)])\n",
        "                    candidate, _ = optimize_acqf(\n",
        "                        UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20\n",
        "                    )\n",
        "                    z = candidate.squeeze()\n",
        "\n",
        "            # 3. Construct Adversarial Example\n",
        "            deltas = self.upsample_projection(z)\n",
        "            x_adv = [t.clone() for t in x_parts_orig]\n",
        "\n",
        "            # Apply perturbation ONLY to selected clients\n",
        "            # (Note: In strict BO, masking inputs creates non-stationarity.\n",
        "            #  Here we assume the GP learns the 'masked' effect as low sensitivity)\n",
        "            for c_idx in active_clients:\n",
        "                # Scale perturbation\n",
        "                x_adv[c_idx] = x_adv[c_idx] + (deltas[c_idx] * 0.5)\n",
        "\n",
        "            # 4. Query System\n",
        "            loss = self.vfl.get_loss(x_adv, y_target)\n",
        "\n",
        "            # 5. Record Data\n",
        "            self.train_x.append(z)\n",
        "            self.train_y.append(loss.detach()) # Maximize Loss\n",
        "\n",
        "            if loss.item() > best_loss:\n",
        "                best_loss = loss.item()\n",
        "\n",
        "            print(f\"Iter {i+1:02d} | Loss: {loss.item():.4f} | Active Clients: {active_clients}\")\n",
        "\n",
        "            # 6. Periodic Update of GP and Importance Scores\n",
        "            if (i + 1) % update_freq == 0:\n",
        "                self.update_surrogate_model()\n",
        "\n",
        "        return best_loss\n",
        "\n",
        "# ==========================================\n",
        "# 3. Main Execution\n",
        "# ==========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # A. Setup Data\n",
        "    data = load_digits()\n",
        "    X = torch.tensor(data.data, dtype=torch.float32)\n",
        "    y = torch.tensor(data.target, dtype=torch.long)\n",
        "    X = (X - X.mean()) / X.std() # Normalize\n",
        "\n",
        "    # B. Setup VFL System (4 Clients, 16 features each)\n",
        "    vfl_env = VFLSystem(n_clients=4, feature_dim=64)\n",
        "\n",
        "    # (Optional) Pre-train VFL model briefly so attack is meaningful\n",
        "    # For demo, we assume random weights or just run as is.\n",
        "    print(\"VFL System Initialized.\")\n",
        "\n",
        "    # C. Run Attack on a single sample\n",
        "    target_idx = 0\n",
        "    attacker = CIBOAttacker(vfl_env, budget_T=2, latent_dim_per_client=4)\n",
        "\n",
        "    final_loss = attacker.run_attack(X[target_idx], y[target_idx], n_iters=25)\n",
        "    print(f\"\\nAttack Complete. Best Loss Achieved: {final_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOcpMPttcxsW",
        "outputId": "39d5f197-9b88-4eef-f7ba-a1da77759309"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VFL System Initialized.\n",
            "\n",
            "--- Starting CIBO-VFL Attack (T=2) ---\n",
            "Iter 01 | Loss: 2.4335 | Active Clients: [0, 1, 2, 3]\n",
            "Iter 02 | Loss: 2.4335 | Active Clients: [0, 1, 2, 3]\n",
            "Iter 03 | Loss: 2.4335 | Active Clients: [0, 1, 2, 3]\n",
            "Iter 04 | Loss: 2.4335 | Active Clients: [0, 1, 2, 3]\n",
            "Iter 05 | Loss: 2.4335 | Active Clients: [0, 1, 2, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/botorch/models/utils/assorted.py:271: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "  check_min_max_scaling(\n",
            "/usr/local/lib/python3.12/dist-packages/botorch/models/utils/assorted.py:274: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([0.], dtype=torch.float64), mean = tensor([0.], dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
            "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Info] Updated Client Importance: [5.771 5.771 5.771 5.771]\n",
            "Iter 06 | Loss: 2.4119 | Active Clients: [1, 0]\n",
            "Iter 07 | Loss: 2.4115 | Active Clients: [1, 3]\n",
            "Iter 08 | Loss: 2.4327 | Active Clients: [3, 2]\n",
            "Iter 09 | Loss: 2.3952 | Active Clients: [2, 3]\n",
            "Iter 10 | Loss: 2.4096 | Active Clients: [0, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/botorch/models/utils/assorted.py:271: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "  check_min_max_scaling(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Info] Updated Client Importance: [5.771 5.771 5.771 5.771]\n",
            "Iter 11 | Loss: 2.4212 | Active Clients: [3, 2]\n",
            "Iter 12 | Loss: 2.4260 | Active Clients: [0, 1]\n",
            "Iter 13 | Loss: 2.4211 | Active Clients: [1, 3]\n",
            "Iter 14 | Loss: 2.4318 | Active Clients: [3, 0]\n",
            "Iter 15 | Loss: 2.4304 | Active Clients: [0, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/botorch/models/utils/assorted.py:271: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "  check_min_max_scaling(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [Info] Updated Client Importance: [5.771 5.771 5.771 5.771]\n",
            "Iter 16 | Loss: 2.4447 | Active Clients: [3, 2]\n",
            "Iter 17 | Loss: 2.4203 | Active Clients: [2, 1]\n",
            "Iter 18 | Loss: 2.4297 | Active Clients: [1, 0]\n",
            "Iter 19 | Loss: 2.4332 | Active Clients: [2, 0]\n",
            "Iter 20 | Loss: 2.4254 | Active Clients: [1, 2]\n",
            "  [Info] Updated Client Importance: [5.77  5.769 5.77  5.77 ]\n",
            "Iter 21 | Loss: 2.4467 | Active Clients: [3, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/botorch/models/utils/assorted.py:271: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "  check_min_max_scaling(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 22 | Loss: 2.4178 | Active Clients: [2, 0]\n",
            "Iter 23 | Loss: 2.4228 | Active Clients: [3, 0]\n",
            "Iter 24 | Loss: 2.4438 | Active Clients: [3, 1]\n",
            "Iter 25 | Loss: 2.4426 | Active Clients: [0, 2]\n",
            "  [Info] Updated Client Importance: [5.771 5.771 5.77  5.771]\n",
            "\n",
            "Attack Complete. Best Loss Achieved: 2.4467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/botorch/models/utils/assorted.py:271: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
            "  check_min_max_scaling(\n"
          ]
        }
      ]
    }
  ]
}